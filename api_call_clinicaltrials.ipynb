{"cells":[{"cell_type":"markdown","source":["# Create list of all oncology trials from ClinicalTrials.gov api closest to the Subject"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"401788c0-dd1f-4e2a-9411-e36ecd6b6749"},{"cell_type":"code","source":["install.packages(\"janitor\")\n","library(SparkR)\n","library(readr)\n","library(janitor)\n","library(httr2)\n","library(purrr)\n","library(dplyr)\n","library(glue)\n","library(readr)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{}},"id":"c73ef655-8e02-49fe-9ed8-b454a084296c"},{"cell_type":"code","source":["get_studies <- function(usa_zipcode_csv,zipcode,radius,indication){\n","\n","        usa_zipcodes <- read_csv(usa_zipcode_csv) # List of zipcodes with geo location across USA\n","\n","        # Base URL for the API call\n","        base_url <- \"https://clinicaltrials.gov/api/v2/studies\"\n","        \n","        #Get geo location with lat and lon from zipcode from user \n","        zip_lat_lon <- dplyr::filter(usa_zipcodes,zip==zipcode)\n","        geo <- paste(zip_lat_lon$latitude,zip_lat_lon$longitude,paste0(radius,\"mi\"),sep = \",\")\n","        print(paste(\"Geo loc:\", geo))\n","\n","        # Initialize the payload without the skip parameter\n","        payload <- list(\n","        format = \"json\",\n","        markupFormat = \"markdown\",\n","        `query.cond` = indication,\n","        `filter.overallStatus` = \"NOT_YET_RECRUITING|RECRUITING\",\n","        `filter.geo` = glue(\"distance(\",geo,\")\"),\n","        fields = \"NCTId\",\n","        countTotal = \"true\",\n","        pageSize = \"1000\"\n","        )\n","\n","        # Initialize variables for pagination\n","        nextPageToken <- NULL\n","        all_studies <- list()\n","\n","        repeat {\n","        # Update the payload with the nextPageToken if it exists\n","        if (!is.null(nextPageToken)) {\n","            payload$pageToken <- nextPageToken\n","        }\n","        \n","        # Make the API request\n","        response <- request(base_url) |>\n","            req_method(\"GET\") |>\n","            req_url_query(!!!payload) |>\n","            req_perform()\n","        \n","        # Parse the response\n","        res <- resp_body_json(response)\n","        \n","        # Check if there are studies in the response and append them\n","        if (length(res$studies) > 0) {\n","            all_studies <- c(all_studies, res$studies)\n","        } else {\n","            # If no studies, exit the loop\n","            break\n","        }\n","        \n","        # Update the nextPageToken for the next request\n","        nextPageToken <- res$nextPageToken\n","        \n","        # Break the loop if nextPageToken is null or empty, indicating no more pages\n","        if (is.null(nextPageToken) || nextPageToken == \"\") {\n","            break\n","  }\n","}\n","\n","# Convert the list of studies to a data frame\n","df <- purrr::map_dfr(all_studies, ~as.data.frame(.x))\n","# Print out the total number of records fetched\n","print(paste(\"Total records fetched:\", nrow(df)))\n","\n","return(df)\n","}"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{}},"id":"94a22097-dbf7-48ef-be41-49a7deab381d"}],"metadata":{"language_info":{"name":"r"},"kernel_info":{"name":"synapse_pyspark"},"microsoft":{"language":"r"},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"}},"nbformat":4,"nbformat_minor":5}